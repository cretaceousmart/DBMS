{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "import sys \n",
    "sys.path.append('/app/')\n",
    "RANDOM_SEED = 42\n",
    "pl.seed_everything(seed=RANDOM_SEED)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Segmentation model (Transformer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import torch\n",
    "logging.disable(logging.CRITICAL)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "exp_args = {\n",
    "    \"encoder\": \"root-interval\",\n",
    "}\n",
    "\n",
    "segmentation_train_args = {\n",
    "    \"seed\": 42,\n",
    "    # \"test_mode\": False,\n",
    "    # \"full_chord\": False,\n",
    "    # \"disable_wandb\": False,\n",
    "    \"wandb_run_name\": \"transformer_test_run\",\n",
    "    \"out\": \"/app/segmentation_out\",\n",
    "    \"source_input_dim\": 3,\n",
    "    \"model_dim\": 64,  # Transformer ÂÜÖÈÉ®‰ΩøÁî®ÁöÑÈöêËóèÂ±ÇÁª¥Â∫¶\n",
    "    \"feedforward_dim\": 128,  # Transformer ÁöÑÂâçÈ¶àÁΩëÁªúÁª¥Â∫¶\n",
    "    \"num_classes\": 14,  # È¢ÑÊµãÁöÑÁ±ªÂà´Êï∞Ôºàsection label ÁöÑÁ±ªÂà´Êï∞Ôºâ\n",
    "    \"num_heads\": 8,  # Â§öÂ§¥Ê≥®ÊÑèÂäõÊú∫Âà∂‰∏≠Â§¥ÁöÑÊï∞Èáè\n",
    "    \"num_layers\": 6,  # Transformer Ê®°Âûã‰∏≠ÁºñÁ†ÅÂô®ÂíåËß£Á†ÅÂô®ÁöÑÂ±ÇÊï∞\n",
    "    \"decoder_max_length\": 500,  # Ëß£Á†ÅÂô®ÁöÑÊúÄÂ§ßÂ∫èÂàóÈïøÂ∫¶\n",
    "    \"init_method\": \"xavier\", # or orthogonal\n",
    "\n",
    "    \"max_epochs\":1,\n",
    "    \"batch_size\": 128,\n",
    "    \"device\": device,  # ËÆ≠ÁªÉÊ®°Âûã‰ΩøÁî®ÁöÑËÆæÂ§á\n",
    "    \"lr\": 0.001,  # Â≠¶‰π†Áéá\n",
    "    \"warmup\": 100,  # Â≠¶‰π†ÁéáÈ¢ÑÁÉ≠Ê≠•Êï∞\n",
    "    \"factor\": 0.5,\n",
    "    \"patience\": 5,\n",
    "    \"max_iters\": 1,  # ËÆ≠ÁªÉÁöÑÊúÄÂ§ßËø≠‰ª£Ê¨°Êï∞\n",
    "    \"dropout\": 0.1,  # Âú®Ê®°Âûã‰∏≠Â∫îÁî®ÁöÑ dropout ÊØîÁéá\n",
    "    \"input_dropout\": 0.1,  # Âú®ËæìÂÖ•ÁâπÂæÅ‰∏äÂ∫îÁî®ÁöÑ dropout ÊØîÁéá\n",
    "}\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python /app/tasks/segmentation/trainning_function/transformer_train.py --encoder root-interval --seed 42 --wandb_run_name transformer_test_run --out /app/segmentation_out --source_input_dim 3 --model_dim 64 --feedforward_dim 128 --num_classes 14 --num_heads 8 --num_layers 6 --decoder_max_length 500 --init_method xavier --max_epochs 1 --batch_size 128 --device cuda --lr 0.001 --warmup 100 --factor 0.5 --patience 5 --max_iters 1 --dropout 0.1 --input_dropout 0.1\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "# Auto generate a Linux command\n",
    "command_parts = [\"python /app/tasks/segmentation/trainning_function/transformer_train.py\"]\n",
    "\n",
    "for arg, value in exp_args.items():\n",
    "    command_parts.append(f\"--{arg} {value}\")\n",
    "\n",
    "for arg, value in segmentation_train_args.items():\n",
    "    command_parts.append(f\"--{arg} {value}\")\n",
    "\n",
    "command = \" \".join(command_parts)\n",
    "print(command)\n",
    "\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcretaceousmart\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.16.0 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/app/tasks/segmentation/wandb/run-20231123_155256-9lz56fad\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mtransformer_test_run\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/cretaceousmart/Segmentation_with_Transformer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/cretaceousmart/Segmentation_with_Transformer/runs/9lz56fad\u001b[0m\n",
      " 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè          | 649/890 [00:00<00:00, 814.15it/s]Track 974 not parsable\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 890/890 [00:01<00:00, 804.74it/s]\n",
      "/usr/local/lib/python3.9/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:604: UserWarning: Checkpoint directory /app/segmentation_out exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "/usr/local/lib/python3.9/dist-packages/pytorch_lightning/trainer/trainer.py:1595: PossibleUserWarning: The number of training batches (5) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Epoch 0:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà     | 4/6 [02:14<01:07, 33.58s/it, loss=2.84, v_num=39]Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pytorch_lightning/trainer/call.py\", line 38, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pytorch_lightning/trainer/trainer.py\", line 645, in _fit_impl\n",
      "    self._run(model, ckpt_path=self.ckpt_path)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1098, in _run\n",
      "    results = self._run_stage()\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1177, in _run_stage\n",
      "    self._run_train()\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1200, in _run_train\n",
      "    self.fit_loop.run()\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pytorch_lightning/loops/loop.py\", line 199, in run\n",
      "    self.advance(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 267, in advance\n",
      "    self._outputs = self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pytorch_lightning/loops/loop.py\", line 199, in run\n",
      "    self.advance(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\", line 230, in advance\n",
      "    self.trainer._call_callback_hooks(\"on_train_batch_end\", batch_end_outputs, batch, batch_idx)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1380, in _call_callback_hooks\n",
      "    fn(self, self.lightning_module, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pytorch_lightning/callbacks/progress/tqdm_progress.py\", line 264, in on_train_batch_end\n",
      "    self.main_progress_bar.set_postfix(self.get_metrics(trainer, pl_module))\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pytorch_lightning/callbacks/progress/base.py\", line 245, in get_metrics\n",
      "    standard_metrics = get_standard_metrics(trainer, pl_module)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pytorch_lightning/callbacks/progress/base.py\", line 274, in get_standard_metrics\n",
      "    avg_training_loss = running_train_loss.cpu().item()\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/app/tasks/segmentation/trainning_function/transformer_train.py\", line 208, in <module>\n",
      "    experiments_df = train(exp_args, segmentation_train_args)\n",
      "  File \"/app/tasks/segmentation/trainning_function/transformer_train.py\", line 110, in train\n",
      "    trainer.fit(transformer_model, data)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pytorch_lightning/trainer/trainer.py\", line 603, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pytorch_lightning/trainer/call.py\", line 63, in _call_and_handle_interrupt\n",
      "    trainer._teardown()\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1161, in _teardown\n",
      "    self.strategy.teardown()\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pytorch_lightning/strategies/strategy.py\", line 492, in teardown\n",
      "    _optimizers_to_device(self.optimizers, torch.device(\"cpu\"))\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/lightning_lite/utilities/optimizer.py\", line 28, in _optimizers_to_device\n",
      "    _optimizer_to_device(opt, device)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/lightning_lite/utilities/optimizer.py\", line 34, in _optimizer_to_device\n",
      "    optimizer.state[p] = apply_to_collection(v, Tensor, move_data_to_device, device)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/lightning_utilities/core/apply_func.py\", line 59, in apply_to_collection\n",
      "    v = apply_to_collection(\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/lightning_utilities/core/apply_func.py\", line 51, in apply_to_collection\n",
      "    return function(data, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/lightning_lite/utilities/apply_func.py\", line 101, in move_data_to_device\n",
      "    return apply_to_collection(batch, dtype=_TransferableDataType, function=batch_to)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/lightning_utilities/core/apply_func.py\", line 51, in apply_to_collection\n",
      "    return function(data, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/lightning_lite/utilities/apply_func.py\", line 95, in batch_to\n",
      "    data_output = data.to(device, **kwargs)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pytorch_lightning/trainer/call.py\", line 38, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pytorch_lightning/trainer/trainer.py\", line 645, in _fit_impl\n",
      "    self._run(model, ckpt_path=self.ckpt_path)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1098, in _run\n",
      "    results = self._run_stage()\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1177, in _run_stage\n",
      "    self._run_train()\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1200, in _run_train\n",
      "    self.fit_loop.run()\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pytorch_lightning/loops/loop.py\", line 199, in run\n",
      "    self.advance(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 267, in advance\n",
      "    self._outputs = self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pytorch_lightning/loops/loop.py\", line 199, in run\n",
      "    self.advance(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\", line 230, in advance\n",
      "    self.trainer._call_callback_hooks(\"on_train_batch_end\", batch_end_outputs, batch, batch_idx)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1380, in _call_callback_hooks\n",
      "    fn(self, self.lightning_module, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pytorch_lightning/callbacks/progress/tqdm_progress.py\", line 264, in on_train_batch_end\n",
      "    self.main_progress_bar.set_postfix(self.get_metrics(trainer, pl_module))\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pytorch_lightning/callbacks/progress/base.py\", line 245, in get_metrics\n",
      "    standard_metrics = get_standard_metrics(trainer, pl_module)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pytorch_lightning/callbacks/progress/base.py\", line 274, in get_standard_metrics\n",
      "    avg_training_loss = running_train_loss.cpu().item()\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/app/tasks/segmentation/trainning_function/transformer_train.py\", line 208, in <module>\n",
      "    experiments_df = train(exp_args, segmentation_train_args)\n",
      "  File \"/app/tasks/segmentation/trainning_function/transformer_train.py\", line 110, in train\n",
      "    trainer.fit(transformer_model, data)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pytorch_lightning/trainer/trainer.py\", line 603, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pytorch_lightning/trainer/call.py\", line 63, in _call_and_handle_interrupt\n",
      "    trainer._teardown()\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1161, in _teardown\n",
      "    self.strategy.teardown()\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pytorch_lightning/strategies/strategy.py\", line 492, in teardown\n",
      "    _optimizers_to_device(self.optimizers, torch.device(\"cpu\"))\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/lightning_lite/utilities/optimizer.py\", line 28, in _optimizers_to_device\n",
      "    _optimizer_to_device(opt, device)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/lightning_lite/utilities/optimizer.py\", line 34, in _optimizer_to_device\n",
      "    optimizer.state[p] = apply_to_collection(v, Tensor, move_data_to_device, device)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/lightning_utilities/core/apply_func.py\", line 59, in apply_to_collection\n",
      "    v = apply_to_collection(\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/lightning_utilities/core/apply_func.py\", line 51, in apply_to_collection\n",
      "    return function(data, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/lightning_lite/utilities/apply_func.py\", line 101, in move_data_to_device\n",
      "    return apply_to_collection(batch, dtype=_TransferableDataType, function=batch_to)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/lightning_utilities/core/apply_func.py\", line 51, in apply_to_collection\n",
      "    return function(data, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/lightning_lite/utilities/apply_func.py\", line 95, in batch_to\n",
      "    data_output = data.to(device, **kwargs)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[31m(failed 1).\u001b[0m Press Control-C to abort syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: - 0.005 MB of 0.005 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train/loss ‚ñà‚ñÖ‚ñÜ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val/loss ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train/loss 2.77592\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val/loss 2.83512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mtransformer_test_run\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/cretaceousmart/Segmentation_with_Transformer/runs/9lz56fad\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ô∏è‚ö° View job at \u001b[34m\u001b[4mhttps://wandb.ai/cretaceousmart/Segmentation_with_Transformer/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjExNzk2NjMwMg==/version_details/v2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20231123_155256-9lz56fad/logs\u001b[0m\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "# Excecute the Linux command\n",
    "!{command}\n",
    "print(\"done!\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1a065321f2d93fd20f60a317fd78c7406ef3cd4260c4249e728d2806e6b26b96"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
