{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Madmom for Chords Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install python libray (TODO: Add to requirement.txt for Docker)\n",
    "\n",
    "# pip install pandas==1.3.5\n",
    "# pip install numpy==1.19.5\n",
    "# pip install scipy==1.10\n",
    "# pip install matplotlib==3.6\n",
    "# pip install madmom\n",
    "\n",
    "# install ffmpeg on Ubuntu\n",
    "# apt update\n",
    "# apt install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/app')\n",
    "from evaluate import load_pitchclass2vec_model\n",
    "\n",
    "from collections import defaultdict\n",
    "from itertools import groupby\n",
    "import re\n",
    "\n",
    "print(\"done\")\n",
    "# RANDOM_SEED = 42\n",
    "# pl.seed_everything(seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: 0.00, End: 4.30, Chord: E:maj\n",
      "Start: 4.30, End: 7.50, Chord: C#:min\n",
      "Start: 7.50, End: 10.40, Chord: F#:maj\n",
      "Start: 10.40, End: 11.60, Chord: D#:min\n",
      "Start: 11.60, End: 13.00, Chord: B:maj\n",
      "Start: 13.00, End: 13.90, Chord: G#:min\n",
      "Start: 13.90, End: 15.20, Chord: F#:maj\n",
      "Start: 15.20, End: 22.20, Chord: E:maj\n",
      "Start: 22.20, End: 25.00, Chord: C#:min\n",
      "Start: 25.00, End: 25.80, Chord: F#:maj\n",
      "Start: 25.80, End: 26.20, Chord: D#:min\n",
      "Start: 26.20, End: 30.20, Chord: B:maj\n",
      "Start: 30.20, End: 31.00, Chord: D#:min\n",
      "Start: 31.00, End: 32.20, Chord: F#:maj\n",
      "Start: 32.20, End: 38.60, Chord: E:maj\n",
      "Start: 38.60, End: 41.20, Chord: N\n",
      "Start: 41.20, End: 42.50, Chord: A:maj\n",
      "Start: 42.50, End: 47.30, Chord: B:maj\n",
      "Start: 47.30, End: 48.50, Chord: G#:min\n",
      "Start: 48.50, End: 49.40, Chord: G#:maj\n",
      "Start: 49.40, End: 50.70, Chord: N\n",
      "Start: 50.70, End: 53.80, Chord: E:maj\n",
      "Start: 53.80, End: 54.80, Chord: C:maj\n",
      "Start: 54.80, End: 56.10, Chord: E:maj\n",
      "Start: 56.10, End: 58.30, Chord: N\n",
      "Start: 58.30, End: 59.00, Chord: B:maj\n",
      "Start: 59.00, End: 63.30, Chord: E:maj\n",
      "Start: 63.30, End: 66.30, Chord: C#:min\n",
      "Start: 66.30, End: 68.50, Chord: F#:maj\n",
      "Start: 68.50, End: 69.90, Chord: B:maj\n",
      "Start: 69.90, End: 71.70, Chord: D#:min\n",
      "Start: 71.70, End: 72.90, Chord: G#:min\n",
      "Start: 72.90, End: 74.10, Chord: F#:maj\n",
      "Start: 74.10, End: 80.40, Chord: E:maj\n",
      "Start: 80.40, End: 83.80, Chord: C#:min\n",
      "Start: 83.80, End: 89.20, Chord: B:maj\n",
      "Start: 89.20, End: 89.90, Chord: D#:min\n",
      "Start: 89.90, End: 91.20, Chord: F#:maj\n",
      "Start: 91.20, End: 97.70, Chord: E:maj\n",
      "Start: 97.70, End: 100.90, Chord: C#:min\n",
      "Start: 100.90, End: 101.70, Chord: F#:maj\n",
      "Start: 101.70, End: 106.20, Chord: B:maj\n",
      "Start: 106.20, End: 108.30, Chord: F#:maj\n",
      "Start: 108.30, End: 114.70, Chord: E:maj\n",
      "Start: 114.70, End: 118.40, Chord: C#:min\n",
      "Start: 118.40, End: 124.10, Chord: B:maj\n",
      "Start: 124.10, End: 125.50, Chord: F#:maj\n",
      "Start: 125.50, End: 132.20, Chord: E:maj\n",
      "Start: 132.20, End: 135.30, Chord: C#:min\n",
      "Start: 135.30, End: 136.20, Chord: F#:maj\n",
      "Start: 136.20, End: 137.10, Chord: D#:min\n",
      "Start: 137.10, End: 140.90, Chord: B:maj\n",
      "Start: 140.90, End: 141.50, Chord: D#:min\n",
      "Start: 141.50, End: 142.60, Chord: F#:maj\n",
      "Start: 142.60, End: 149.00, Chord: E:maj\n",
      "Start: 149.00, End: 152.20, Chord: C#:min\n",
      "Start: 152.20, End: 153.10, Chord: F#:maj\n",
      "Start: 153.10, End: 156.60, Chord: D#:min\n",
      "Start: 156.60, End: 157.70, Chord: B:maj\n",
      "Start: 157.70, End: 159.70, Chord: G#:maj\n",
      "Start: 159.70, End: 166.20, Chord: E:maj\n",
      "Start: 166.20, End: 169.80, Chord: C#:min\n",
      "Start: 169.80, End: 174.90, Chord: B:maj\n",
      "Start: 174.90, End: 175.70, Chord: D#:min\n",
      "Start: 175.70, End: 176.90, Chord: F#:maj\n",
      "Start: 176.90, End: 184.50, Chord: E:maj\n",
      "Start: 184.50, End: 186.70, Chord: C#:min\n",
      "Start: 186.70, End: 187.50, Chord: F#:maj\n",
      "Start: 187.50, End: 188.30, Chord: D#:min\n",
      "Start: 188.30, End: 191.60, Chord: B:maj\n",
      "Start: 191.60, End: 192.30, Chord: D#:min\n",
      "Start: 192.30, End: 194.00, Chord: F#:maj\n",
      "Start: 194.00, End: 200.20, Chord: E:maj\n",
      "Start: 200.20, End: 203.90, Chord: C#:min\n",
      "Start: 203.90, End: 204.60, Chord: B:maj\n",
      "Start: 204.60, End: 205.80, Chord: D#:min\n",
      "Start: 205.80, End: 209.90, Chord: B:maj\n",
      "Start: 209.90, End: 211.20, Chord: F#:maj\n",
      "Start: 211.20, End: 218.10, Chord: E:maj\n",
      "Start: 218.10, End: 221.10, Chord: C#:min\n",
      "Start: 221.10, End: 221.80, Chord: F#:maj\n",
      "Start: 221.80, End: 222.70, Chord: D#:min\n",
      "Start: 222.70, End: 226.50, Chord: B:maj\n",
      "Start: 226.50, End: 227.10, Chord: D#:min\n",
      "Start: 227.10, End: 228.30, Chord: F#:maj\n",
      "Start: 228.30, End: 239.10, Chord: E:maj\n",
      "Start: 239.10, End: 241.10, Chord: N\n",
      "Start: 241.10, End: 242.20, Chord: C#:maj\n",
      "Start: 242.20, End: 244.50, Chord: N\n",
      "Start: 244.50, End: 245.70, Chord: D#:maj\n",
      "Start: 245.70, End: 247.20, Chord: F#:maj\n",
      "Start: 247.20, End: 247.80, Chord: D#:maj\n",
      "Start: 247.80, End: 249.00, Chord: D#:min\n",
      "Start: 249.00, End: 250.20, Chord: B:maj\n",
      "Start: 250.20, End: 250.70, Chord: D#:min\n",
      "Start: 250.70, End: 252.40, Chord: N\n",
      "Start: 252.40, End: 253.50, Chord: D#:maj\n",
      "Start: 253.50, End: 254.30, Chord: B:maj\n",
      "Start: 254.30, End: 255.30, Chord: D#:maj\n",
      "Start: 255.30, End: 258.50, Chord: C#:maj\n",
      "Start: 258.50, End: 260.50, Chord: F#:maj\n",
      "Start: 260.50, End: 269.90, Chord: E:maj\n",
      "Start: 269.90, End: 272.40, Chord: C#:min\n",
      "Start: 272.40, End: 273.20, Chord: F#:maj\n",
      "Start: 273.20, End: 273.90, Chord: D#:min\n",
      "Start: 273.90, End: 277.70, Chord: B:maj\n",
      "Start: 277.70, End: 279.80, Chord: F#:maj\n",
      "Start: 279.80, End: 286.30, Chord: E:maj\n",
      "Start: 286.30, End: 289.40, Chord: C#:min\n",
      "Start: 289.40, End: 290.20, Chord: E:maj\n",
      "Start: 290.20, End: 290.90, Chord: D#:min\n",
      "Start: 290.90, End: 294.90, Chord: B:maj\n",
      "Start: 294.90, End: 296.20, Chord: D#:min\n",
      "Start: 296.20, End: 296.90, Chord: F#:maj\n",
      "Start: 296.90, End: 299.00, Chord: E:maj\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# 导入所需的模块\n",
    "import numpy as np\n",
    "from madmom.features.chords import CNNChordFeatureProcessor, CRFChordRecognitionProcessor\n",
    "from madmom.processors import SequentialProcessor\n",
    "\n",
    "# 音频文件路径\n",
    "audio_file = '/app/jie_test_music/Drake_Passionfruit.mp3'\n",
    "\n",
    "# 创建一个特征提取器实例\n",
    "feature_processor = CNNChordFeatureProcessor()\n",
    "\n",
    "# 创建一个和弦识别器实例\n",
    "chord_recognizer = CRFChordRecognitionProcessor()\n",
    "\n",
    "# 将两个处理器串联成一个序列处理器\n",
    "sequential_processor = SequentialProcessor([feature_processor, chord_recognizer])\n",
    "\n",
    "# 应用处理器到音频文件上，识别和弦\n",
    "chords = sequential_processor(audio_file)\n",
    "\n",
    "# 打印识别出的和弦\n",
    "for chord in chords:\n",
    "    start, end, label = chord\n",
    "    print(f\"Start: {start:.2f}, End: {end:.2f}, Chord: {label}\")\n",
    "\n",
    "# 如果你想将和弦信息保存到一个文件中，你可以这样做：\n",
    "# with open('/app/jie_test_music/Drake_Passionfruit_chords.txt', 'w') as f:\n",
    "#     for chord in chords:\n",
    "#         f.write(f\"{chord[0]:.2f}\\t{chord[1]:.2f}\\t{chord[2]}\\n\")\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115\n",
      "<class 'numpy.ndarray'>\n",
      "[(0. ,  4.3, 'E:maj') (4.3,  7.5, 'C#:min') (7.5, 10.4, 'F#:maj')]\n"
     ]
    }
   ],
   "source": [
    "# print the info of chords array\n",
    "print(len(chords))\n",
    "print(type(chords))\n",
    "print(chords[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Embed the chord by embedding model (store in /out)\n",
    "def embed_chord(p2v, c):\n",
    "    try:\n",
    "        return p2v[c]\n",
    "    except:\n",
    "        return p2v[\"N\"]\n",
    "\n",
    "# Load the embedding model\n",
    "p2v = load_pitchclass2vec_model(\"root-interval\", \"fasttext\", \"/app/out/first_run_with_whole_ChocoDataSet.ckpt\")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedded_chord_test.shape: (100,)\n",
      "corpus_embedded.shape: (115, 100)\n",
      "\n",
      "\n",
      "embedded_chord_test: [ 1.5023417   1.4714259  -1.8749816  -0.19704878  0.32284945  1.6470559\n",
      " -0.1832118   0.4308313   0.1617653  -2.3423574  -0.94857323 -1.3680321\n",
      "  1.8316647   2.4073575  -0.2145201   1.2042994   0.42670178 -2.555657\n",
      " -3.300817   -0.6872867   0.09748369 -1.297121   -2.6374292   4.260552\n",
      "  0.5044306  -2.362741   -0.6666601  -2.8838537   1.414785   -0.41518974\n",
      " -0.6042384  -0.8536912  -1.0217173   0.46472374  1.2799902   1.5056918\n",
      "  1.0058668   3.063817    1.0289304  -0.2772213   0.95502794  1.1806269\n",
      "  1.7442743  -1.0042367  -1.8859016   3.0172048   2.3404994   2.7114666\n",
      "  0.02019075 -0.02266622 -2.360383   -0.86830443 -0.7102659   1.6148638\n",
      "  0.9213932  -1.3960586   0.41863513  2.1318412  -0.6925771   5.36633\n",
      " -0.15068114  1.1545246  -1.5879536   1.1653125  -0.6584067   3.99355\n",
      " -1.8545915  -1.0097904  -1.0863103  -0.6686289  -3.2702658   1.3489337\n",
      " -1.1630509   1.3578134   2.557721    0.84791994  0.2957012   1.2826614\n",
      " -1.6721066  -2.3765867  -1.8120555  -0.92694604 -1.871063    1.0530306\n",
      "  1.1919786  -1.5109663  -0.23896503  0.34154713  1.6548132  -3.3493075\n",
      " -0.23872113  0.52981985 -0.8934165   1.0729811  -2.9206476   0.48558986\n",
      " -2.3460264  -3.2958345  -0.2250812   0.773461  ]\n"
     ]
    }
   ],
   "source": [
    "chords_str = [chord[2] for chord in chords]\n",
    "embedded_chord_test = embed_chord(p2v,chords_str[0])\n",
    "\n",
    "corpus_embedded = np.stack([\n",
    "    np.mean(np.array([embed_chord(p2v, c) for c in x]), axis=0) for x in chords\n",
    "])\n",
    "\n",
    "print(f\"embedded_chord_test.shape: {embedded_chord_test.shape}\") #The length is 100 because we set 'embedding_dim': 100 in embedding trainning process\n",
    "print(f\"corpus_embedded.shape: {corpus_embedded.shape}\",end='\\n')\n",
    "print('\\n')\n",
    "print(f\"embedded_chord_test: {embedded_chord_test}\")\n",
    "# corpus_embedded = np.stack([\n",
    "#     np.mean(np.array([embed_chord(p2v, c) for c in x]), axis=0) for x in chords\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result after classification:tensor([[[-1.3092,  0.7941,  0.0061,  ..., -1.3589, -0.7658,  1.0796],\n",
      "         [-1.8537,  0.9083, -0.1224,  ..., -1.4891, -1.0478,  1.4031],\n",
      "         [-2.0752,  1.0064, -0.0923,  ..., -1.5634, -1.1503,  1.6124],\n",
      "         ...,\n",
      "         [ 1.2023,  3.1554,  1.2440,  ..., -1.6685,  0.7210,  3.3394],\n",
      "         [ 1.0413,  3.0076,  1.1419,  ..., -1.6034,  0.6502,  3.1438],\n",
      "         [ 0.7760,  2.6215,  0.9623,  ..., -1.4010,  0.5920,  2.6845]]],\n",
      "       device='cuda:0')\n",
      "Result after softmax: tensor([[[-1.3092,  0.7941,  0.0061,  ..., -1.3589, -0.7658,  1.0796],\n",
      "         [-1.8537,  0.9083, -0.1224,  ..., -1.4891, -1.0478,  1.4031],\n",
      "         [-2.0752,  1.0064, -0.0923,  ..., -1.5634, -1.1503,  1.6124],\n",
      "         ...,\n",
      "         [ 1.2023,  3.1554,  1.2440,  ..., -1.6685,  0.7210,  3.3394],\n",
      "         [ 1.0413,  3.0076,  1.1419,  ..., -1.6034,  0.6502,  3.1438],\n",
      "         [ 0.7760,  2.6215,  0.9623,  ..., -1.4010,  0.5920,  2.6845]]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from tasks.segmentation.functional import LSTMBaselineModel\n",
    "import torch \n",
    "\n",
    "# Obtain correct input format\n",
    "corpus_embedded = torch.tensor(corpus_embedded).unsqueeze(0)\n",
    "\n",
    "# Use LSTM model for prediction:\n",
    "CKPT_PATH = '/app/segmentation_out/third_run.ckpt.ckpt'\n",
    "\n",
    "\n",
    "model = LSTMBaselineModel.load_from_checkpoint(CKPT_PATH)\n",
    "\n",
    "\n",
    "model.eval() # evalutaion mode\n",
    "\n",
    "# Move to GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "corpus_embedded = corpus_embedded.to(device)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions = model.evaluation_forward(corpus_embedded)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 115, 11])\n",
      "torch.Size([1, 115, 11])\n"
     ]
    }
   ],
   "source": [
    "print(predictions[0].shape)\n",
    "print(predictions[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: chords_str: ['E:maj', 'C#:min', 'F#:maj', 'D#:min', 'B:maj', 'G#:min', 'F#:maj', 'E:maj', 'C#:min', 'F#:maj', 'D#:min', 'B:maj', 'D#:min', 'F#:maj', 'E:maj', 'N', 'A:maj', 'B:maj', 'G#:min', 'G#:maj', 'N', 'E:maj', 'C:maj', 'E:maj', 'N', 'B:maj', 'E:maj', 'C#:min', 'F#:maj', 'B:maj', 'D#:min', 'G#:min', 'F#:maj', 'E:maj', 'C#:min', 'B:maj', 'D#:min', 'F#:maj', 'E:maj', 'C#:min', 'F#:maj', 'B:maj', 'F#:maj', 'E:maj', 'C#:min', 'B:maj', 'F#:maj', 'E:maj', 'C#:min', 'F#:maj', 'D#:min', 'B:maj', 'D#:min', 'F#:maj', 'E:maj', 'C#:min', 'F#:maj', 'D#:min', 'B:maj', 'G#:maj', 'E:maj', 'C#:min', 'B:maj', 'D#:min', 'F#:maj', 'E:maj', 'C#:min', 'F#:maj', 'D#:min', 'B:maj', 'D#:min', 'F#:maj', 'E:maj', 'C#:min', 'B:maj', 'D#:min', 'B:maj', 'F#:maj', 'E:maj', 'C#:min', 'F#:maj', 'D#:min', 'B:maj', 'D#:min', 'F#:maj', 'E:maj', 'N', 'C#:maj', 'N', 'D#:maj', 'F#:maj', 'D#:maj', 'D#:min', 'B:maj', 'D#:min', 'N', 'D#:maj', 'B:maj', 'D#:maj', 'C#:maj', 'F#:maj', 'E:maj', 'C#:min', 'F#:maj', 'D#:min', 'B:maj', 'F#:maj', 'E:maj', 'C#:min', 'E:maj', 'D#:min', 'B:maj', 'D#:min', 'F#:maj', 'E:maj']\n",
      "\n",
      "\n",
      "Output: predicted_labels: tensor([[ 4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
      "          4,  4,  4, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "         10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "         10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "         10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "         10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "         10, 10, 10, 10, 10, 10, 10]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = torch.argmax(predictions[1], dim=-1)  # shape will be (1, 115)\n",
    "print(f\"Input: chords_str: {chords_str}\")\n",
    "print('\\n')\n",
    "print(f\"Output: predicted_labels: {predicted_labels}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
